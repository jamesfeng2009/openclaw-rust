//! æœ¬åœ° Whisper æ¨¡å‹æ”¯æŒ
//!
//! ä½¿ç”¨ whisper.cpp å®ç°æœ¬åœ°è¯­éŸ³è¯†åˆ«

use async_trait::async_trait;
use openclaw_core::{OpenClawError, Result};

use crate::types::{SttProvider, TranscriptionResult};

/// æœ¬åœ° Whisper é…ç½®
#[derive(Debug, Clone)]
pub struct LocalWhisperConfig {
    /// æ¨¡å‹æ–‡ä»¶è·¯å¾„
    pub model_path: String,
    /// è¯­è¨€ (å¯é€‰ï¼Œè‡ªåŠ¨æ£€æµ‹)
    pub language: Option<String>,
    /// æ˜¯å¦ç¿»è¯‘ä¸ºè‹±æ–‡
    pub translate: bool,
    /// çº¿ç¨‹æ•°
    pub n_threads: i32,
}

impl Default for LocalWhisperConfig {
    fn default() -> Self {
        Self {
            model_path: String::new(),
            language: None,
            translate: false,
            n_threads: 4,
        }
    }
}

/// æœ¬åœ° Whisper STT
pub struct LocalWhisperStt {
    config: LocalWhisperConfig,
}

impl LocalWhisperStt {
    pub fn new(config: LocalWhisperConfig) -> Self {
        Self { config }
    }

    /// æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    pub fn check_model(&self) -> Result<()> {
        let path = std::path::Path::new(&self.config.model_path);
        if !path.exists() {
            return Err(OpenClawError::Config(format!(
                "Whisper æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {}",
                self.config.model_path
            )));
        }
        Ok(())
    }

    /// ä¸‹è½½æ¨¡å‹
    pub async fn download_model(model_type: WhisperModelType) -> Result<String> {
        let models_dir = Self::get_models_dir()?;

        let (filename, url) = match model_type {
            WhisperModelType::Tiny => (
                "ggml-tiny.bin",
                "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.bin",
            ),
            WhisperModelType::TinyEn => (
                "ggml-tiny.en.bin",
                "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.en.bin",
            ),
            WhisperModelType::Base => (
                "ggml-base.bin",
                "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin",
            ),
            WhisperModelType::BaseEn => (
                "ggml-base.en.bin",
                "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.en.bin",
            ),
            WhisperModelType::Small => (
                "ggml-small.bin",
                "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-small.bin",
            ),
            WhisperModelType::Medium => (
                "ggml-medium.bin",
                "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-medium.bin",
            ),
            WhisperModelType::Large => (
                "ggml-large-v3.bin",
                "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-large-v3.bin",
            ),
        };

        let model_path = models_dir.join(filename);

        if model_path.exists() {
            println!("âœ… æ¨¡å‹å·²å­˜åœ¨: {}", model_path.display());
            return Ok(model_path.to_string_lossy().to_string());
        }

        println!("ğŸ“¥ ä¸‹è½½ Whisper æ¨¡å‹: {}", filename);
        println!("   URL: {}", url);

        // åˆ›å»ºç›®å½•
        std::fs::create_dir_all(&models_dir)
            .map_err(|e| OpenClawError::Config(format!("åˆ›å»ºæ¨¡å‹ç›®å½•å¤±è´¥: {}", e)))?;

        // ä¸‹è½½
        let response = reqwest::get(url)
            .await
            .map_err(|e| OpenClawError::Http(format!("ä¸‹è½½æ¨¡å‹å¤±è´¥: {}", e)))?;

        if !response.status().is_success() {
            return Err(OpenClawError::Http(format!(
                "ä¸‹è½½æ¨¡å‹å¤±è´¥: HTTP {}",
                response.status()
            )));
        }

        let bytes = response
            .bytes()
            .await
            .map_err(|e| OpenClawError::Http(format!("è¯»å–æ¨¡å‹æ•°æ®å¤±è´¥: {}", e)))?;

        std::fs::write(&model_path, &bytes)
            .map_err(|e| OpenClawError::Config(format!("ä¿å­˜æ¨¡å‹å¤±è´¥: {}", e)))?;

        println!("âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {}", model_path.display());

        Ok(model_path.to_string_lossy().to_string())
    }

    /// è·å–æ¨¡å‹ç›®å½•
    fn get_models_dir() -> Result<std::path::PathBuf> {
        let home = std::env::var("HOME")
            .or_else(|_| std::env::var("USERPROFILE"))
            .unwrap_or_else(|_| ".".to_string());
        Ok(std::path::PathBuf::from(home)
            .join(".openclaw")
            .join("models"))
    }

    /// åˆ—å‡ºå¯ç”¨æ¨¡å‹
    pub fn list_available_models() -> Vec<WhisperModelInfo> {
        vec![
            WhisperModelInfo {
                name: "tiny".to_string(),
                size_mb: 75,
                languages: 99,
                recommended: false,
                description: "æœ€å°æ¨¡å‹ï¼Œé€Ÿåº¦å¿«ä½†å‡†ç¡®åº¦è¾ƒä½".to_string(),
            },
            WhisperModelInfo {
                name: "tiny.en".to_string(),
                size_mb: 75,
                languages: 1,
                recommended: false,
                description: "ä»…è‹±è¯­ï¼Œé€Ÿåº¦æœ€å¿«".to_string(),
            },
            WhisperModelInfo {
                name: "base".to_string(),
                size_mb: 142,
                languages: 99,
                recommended: true,
                description: "åŸºç¡€æ¨¡å‹ï¼Œå¹³è¡¡é€Ÿåº¦å’Œå‡†ç¡®åº¦".to_string(),
            },
            WhisperModelInfo {
                name: "base.en".to_string(),
                size_mb: 142,
                languages: 1,
                recommended: false,
                description: "ä»…è‹±è¯­ï¼Œå‡†ç¡®åº¦è¾ƒå¥½".to_string(),
            },
            WhisperModelInfo {
                name: "small".to_string(),
                size_mb: 466,
                languages: 99,
                recommended: true,
                description: "å°å‹æ¨¡å‹ï¼Œå‡†ç¡®åº¦è¾ƒå¥½".to_string(),
            },
            WhisperModelInfo {
                name: "medium".to_string(),
                size_mb: 1500,
                languages: 99,
                recommended: false,
                description: "ä¸­å‹æ¨¡å‹ï¼Œå‡†ç¡®åº¦é«˜".to_string(),
            },
            WhisperModelInfo {
                name: "large-v3".to_string(),
                size_mb: 2900,
                languages: 99,
                recommended: false,
                description: "æœ€å¤§æ¨¡å‹ï¼Œå‡†ç¡®åº¦æœ€é«˜".to_string(),
            },
        ]
    }
}

#[async_trait]
impl super::SpeechToText for LocalWhisperStt {
    fn provider(&self) -> SttProvider {
        SttProvider::LocalWhisper
    }

    async fn transcribe(
        &self,
        _audio_data: &[u8],
        _language: Option<&str>,
    ) -> Result<TranscriptionResult> {
        // æ£€æŸ¥æ¨¡å‹
        self.check_model()?;

        // æ³¨æ„: å®é™…çš„ whisper.cpp è°ƒç”¨éœ€è¦ whisper-rs crate
        // è¿™é‡Œæä¾›æ¡†æ¶å®ç°ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦æ·»åŠ ä¾èµ–

        Err(OpenClawError::Config(
            "æœ¬åœ° Whisper éœ€è¦å®‰è£… whisper-rs ä¾èµ–ã€‚è¯·ä½¿ç”¨ OpenAI Whisper API æˆ–å®‰è£…æœ¬åœ°ä¾èµ–"
                .to_string(),
        ))
    }

    async fn is_available(&self) -> bool {
        self.check_model().is_ok()
    }
}

/// Whisper æ¨¡å‹ç±»å‹
#[derive(Debug, Clone, Copy)]
pub enum WhisperModelType {
    Tiny,
    TinyEn,
    Base,
    BaseEn,
    Small,
    Medium,
    Large,
}

/// æ¨¡å‹ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct WhisperModelInfo {
    pub name: String,
    pub size_mb: u64,
    pub languages: u32,
    pub recommended: bool,
    pub description: String,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_list_models() {
        let models = LocalWhisperStt::list_available_models();
        assert!(!models.is_empty());

        let recommended: Vec<_> = models.iter().filter(|m| m.recommended).collect();
        assert!(!recommended.is_empty());
    }

    #[test]
    fn test_default_config() {
        let config = LocalWhisperConfig::default();
        assert_eq!(config.n_threads, 4);
        assert!(!config.translate);
    }
}
